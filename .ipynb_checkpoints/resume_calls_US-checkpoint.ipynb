{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whereas the other notebook is to create a template from the JHU data and start making\n",
    "# API calls from scratch, if that notebook is interrupted, this one will pick up where\n",
    "# that one left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# reading CSV files to create dataframes\n",
    "df_confirmed = pd.read_csv('./csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')\n",
    "\n",
    "df_tMax = pd.read_csv('./csv/tMax_US.csv')\n",
    "df_tMin = pd.read_csv('./csv/tMin_US.csv')\n",
    "df_humidity = pd.read_csv('./csv/humidity_US.csv')\n",
    "df_uvIndex = pd.read_csv('./csv/uv_US.csv')\n",
    "df_cloud = pd.read_csv('./csv/cloud_US.csv')\n",
    "df_precipprob = pd.read_csv('./csv/precip_US.csv')\n",
    "df_dewpoint = pd.read_csv('./csv/dew_US.csv')\n",
    "df_pressure = pd.read_csv('./csv/pressure_US.csv')\n",
    "df_windspeed = pd.read_csv('./csv/wind_US.csv')\n",
    "df_ozone = pd.read_csv('./csv/ozone_US.csv')\n",
    "df_sunrise = pd.read_csv('./csv/sunrise_US.csv')\n",
    "df_sunset = pd.read_csv('./csv/sunset_US.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>8/3/20</th>\n",
       "      <th>8/4/20</th>\n",
       "      <th>8/5/20</th>\n",
       "      <th>8/6/20</th>\n",
       "      <th>8/7/20</th>\n",
       "      <th>8/8/20</th>\n",
       "      <th>8/9/20</th>\n",
       "      <th>8/10/20</th>\n",
       "      <th>8/11/20</th>\n",
       "      <th>8/12/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84001007</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84001009</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "3  84001007   US  USA    840  1007.0     Bibb        Alabama             US   \n",
       "4  84001009   US  USA    840  1009.0   Blount        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 8/3/20  8/4/20  8/5/20  8/6/20  8/7/20  8/8/20  \\\n",
       "0  32.539527 -86.644082  ...      0       0       0       0       0       0   \n",
       "1  30.727750 -87.722071  ...      0       0       0       0       0       0   \n",
       "2  31.868263 -85.387129  ...      0       0       0       0       0       0   \n",
       "3  32.996421 -87.125115  ...      0       0       0       0       0       0   \n",
       "4  33.982109 -86.567906  ...      0       0       0       0       0       0   \n",
       "\n",
       "   8/9/20  8/10/20  8/11/20  8/12/20  \n",
       "0       0        0        0        0  \n",
       "1       0        0        0        0  \n",
       "2       0        0        0        0  \n",
       "3       0        0        0        0  \n",
       "4       0        0        0        0  \n",
       "\n",
       "[5 rows x 235 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tMax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resuming the API calls\n",
    "\n",
    "# Code to increase number of retries on connection errors,\n",
    "# and also to give it some time.\n",
    "# Found on https://stackoverflow.com/questions/15431044/can-i-set-max-retries-for-requests-request\n",
    "# And https://findwork.dev/blog/advanced-usage-python-requests-timeouts-retries-hooks/\n",
    "\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "retries = Retry(total=30,\n",
    "                backoff_factor=0.1,\n",
    "                status_forcelist=[ 429, 500, 502, 503, 504 ],\n",
    "                method_whitelist=[\"HEAD\", \"GET\", \"OPTIONS\"])\n",
    "\n",
    "adapter = HTTPAdapter(max_retries=retries)\n",
    "http = requests.Session()\n",
    "http.mount(\"https://\", adapter)\n",
    "http.mount(\"http://\", adapter)\n",
    "\n",
    "# pull data from darksky weather API\n",
    "\n",
    "# Columns to be skipped when iterating through the DataFrame\n",
    "do_not_include = ['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "                 'Country_Region', 'Lat', 'Long_', 'Combined_Key']\n",
    "\n",
    "#Darksky API key\n",
    "API_KEY = '723a6f9dbda64ae1e0b9fdde14ba752e'\n",
    "\n",
    "# counter\n",
    "counter = 0\n",
    "\n",
    "# Dummy value in case of errors\n",
    "dummy = -1000\n",
    "\n",
    "# variable for determining how many API calls between writing data to CSV\n",
    "write_var = 1000\n",
    "\n",
    "# Start iterating through the date columns\n",
    "for x in df_tMax.columns.values:\n",
    "    \n",
    "    # Skip the columns that are not dates\n",
    "    if (x not in do_not_include):\n",
    "        \n",
    "        # Create Unix time stamp out of the date column\n",
    "        t = pd.to_datetime(df_tMax[x].name)\n",
    "        t = int(t.value / 10**9)\n",
    "        t = str(t)\n",
    "                \n",
    "        # Start iterating through the rows (locations)\n",
    "        for y in range(df_tMax['1/22/20'].values.size):\n",
    "            \n",
    "            # Only do API call if the cell value is 0\n",
    "            if str(df_tMax.iloc[y][x]) == '0':\n",
    "                \n",
    "                print('Cell is 0')\n",
    "                \n",
    "                # latitude and longitude coordinates of the row to be passed to the API            \n",
    "                latitude = str(df_tMax.iloc[y][8])\n",
    "                longitude = str(df_tMax.iloc[y][9])\n",
    "\n",
    "                # Building the URL for the API get\n",
    "                url = 'https://api.darksky.net/forecast/' + API_KEY + '/' + latitude + \",\" + longitude + ',' + t\n",
    "                url = url + '?exclude=currently,flags&units=si'\n",
    "\n",
    "                # Getting the API call\n",
    "                # using the retry error handling established above\n",
    "                response = http.get(url)\n",
    "                \n",
    "                # Putting the API response into the JSON thing\n",
    "                info = json.loads(response.content)\n",
    "\n",
    "                # adding error handling in case something is wrong with the JSON response\n",
    "                try:\n",
    "\n",
    "                    # Making a variable to more easily acccess JSON response data\n",
    "                    easy_info = info['daily']['data'][0]\n",
    "\n",
    "                    # Reading the JSON data\n",
    "                    tMax = easy_info['temperatureHigh']\n",
    "                    tMin = easy_info['temperatureLow']\n",
    "                    hum = easy_info['humidity'] * 100\n",
    "                    uvee = easy_info['uvIndex']\n",
    "                    clouds = easy_info['cloudCover'] * 100\n",
    "                    precip = easy_info['precipProbability'] * 100\n",
    "                    dew = easy_info['dewPoint']\n",
    "                    pressure = easy_info['pressure']\n",
    "                    wind = easy_info['windSpeed']\n",
    "                    ozone = easy_info['ozone']\n",
    "                    sunrise = easy_info['sunriseTime']\n",
    "                    sunset = easy_info['sunsetTime']\n",
    "\n",
    "                except:\n",
    "\n",
    "                    # Creating dummy values in case of error\n",
    "                    print('Error encountered')\n",
    "                    tMax = dummy\n",
    "                    tMin = dummy\n",
    "                    hum = dummy\n",
    "                    uvee = dummy\n",
    "                    clouds = dummy\n",
    "                    precip = dummy\n",
    "                    dew = dummy\n",
    "                    pressure = dummy\n",
    "                    wind = dummy\n",
    "                    ozone = dummy\n",
    "                    sunrise = dummy\n",
    "                    sunset = dummy\n",
    "\n",
    "                # Recording the data into the respective dataframes\n",
    "                df_tMax.at[y, x] = tMax\n",
    "                df_tMin.at[y, x] = tMin\n",
    "                df_humidity.at[y, x] = hum\n",
    "                df_uvIndex.at[y, x] = uvee\n",
    "                df_cloud.at[y, x] = clouds\n",
    "                df_precipprob.at[y, x] = precip\n",
    "                df_dewpoint.at[y, x] = dew\n",
    "                df_pressure.at[y, x] = pressure\n",
    "                df_windspeed.at[y, x] = wind\n",
    "                df_ozone.at[y, x] = ozone\n",
    "                df_sunrise.at[y,x] = sunrise\n",
    "                df_sunset.at[y,x] = sunset\n",
    "            \n",
    "            counter = counter + 1\n",
    "            print(counter)\n",
    "\n",
    "            # writing CSVs of what I've got so far, for every write_var API calls\n",
    "            if counter % write_var == 0:\n",
    "                \n",
    "                print('1000 API calls')\n",
    "                df_tMax.to_csv('./csv/tMax_US.csv', index=False)\n",
    "                df_tMin.to_csv('./csv/tMin_US.csv', index=False)\n",
    "                df_humidity.to_csv('./csv/humidity_US.csv', index=False)\n",
    "                df_uvIndex.to_csv('./csv/uv_US.csv', index=False)\n",
    "                df_cloud.to_csv('./csv/cloud_US.csv', index=False)\n",
    "                df_precipprob.to_csv('./csv/precip_US.csv', index=False)\n",
    "                df_dewpoint.to_csv('./csv/dew_US.csv', index=False)\n",
    "                df_pressure.to_csv('./csv/pressure_US.csv', index=False)\n",
    "                df_windspeed.to_csv('./csv/wind_US.csv', index=False)\n",
    "                df_ozone.to_csv('./csv/ozone_US.csv', index=False)\n",
    "                df_sunrise.to_csv('./csv/sunrise_US.csv', index=False)\n",
    "                df_sunset.to_csv('./csv/sunset_US.csv', index=False)\n",
    "\n",
    "# Writing final data to csv\n",
    "print('Final data write')\n",
    "df_tMax.to_csv('./csv/tMax_US.csv', index=False)\n",
    "df_tMin.to_csv('./csv/tMin_US.csv', index=False)\n",
    "df_humidity.to_csv('./csv/humidity_US.csv', index=False)\n",
    "df_uvIndex.to_csv('./csv/uv_US.csv', index=False)\n",
    "df_cloud.to_csv('./csv/cloud_US.csv', index=False)\n",
    "df_precipprob.to_csv('./csv/precip_US.csv', index=False)\n",
    "df_dewpoint.to_csv('./csv/dew_US.csv', index=False)\n",
    "df_pressure.to_csv('./csv/pressure_US.csv', index=False)\n",
    "df_windspeed.to_csv('./csv/wind_US.csv', index=False)\n",
    "df_ozone.to_csv('./csv/ozone_US.csv', index=False)\n",
    "df_sunrise.to_csv('./csv/sunrise_US.csv', index=False)\n",
    "df_sunset.to_csv('./csv/sunset_US.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing data to csv\n",
    "df_tMax.to_csv('./csv/tMax_US.csv', index=False)\n",
    "df_tMin.to_csv('./csv/tMin_US.csv', index=False)\n",
    "df_humidity.to_csv('./csv/humidity_US.csv', index=False)\n",
    "df_uvIndex.to_csv('./csv/uv_US.csv', index=False)\n",
    "df_cloud.to_csv('./csv/cloud_US.csv', index=False)\n",
    "df_precipprob.to_csv('./csv/precip_US.csv', index=False)\n",
    "df_dewpoint.to_csv('./csv/dew_US.csv', index=False)\n",
    "df_pressure.to_csv('./csv/pressure_US.csv', index=False)\n",
    "df_windspeed.to_csv('./csv/wind_US.csv', index=False)\n",
    "df_ozone.to_csv('./csv/ozone_US.csv', index=False)\n",
    "df_sunrise.to_csv('./csv/sunrise_US.csv', index=False)\n",
    "df_sunset.to_csv('./csv/sunset_US.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cell\n",
    "\n",
    "# Resuming the API calls\n",
    "\n",
    "# Code to increase number of retries on connection errors,\n",
    "# and also to give it some time.\n",
    "# Found on https://stackoverflow.com/questions/15431044/can-i-set-max-retries-for-requests-request\n",
    "# And https://findwork.dev/blog/advanced-usage-python-requests-timeouts-retries-hooks/\n",
    "\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "retries = Retry(total=30,\n",
    "                backoff_factor=0.1,\n",
    "                status_forcelist=[ 429, 500, 502, 503, 504 ],\n",
    "                method_whitelist=[\"HEAD\", \"GET\", \"OPTIONS\"])\n",
    "\n",
    "adapter = HTTPAdapter(max_retries=retries)\n",
    "http = requests.Session()\n",
    "http.mount(\"https://\", adapter)\n",
    "http.mount(\"http://\", adapter)\n",
    "\n",
    "# pull data from darksky weather API\n",
    "\n",
    "# Columns to be skipped when iterating through the DataFrame\n",
    "do_not_include = ['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "                 'Country_Region', 'Lat', 'Long_', 'Combined_Key']\n",
    "\n",
    "#Darksky API key\n",
    "API_KEY = '723a6f9dbda64ae1e0b9fdde14ba752e'\n",
    "\n",
    "# counter\n",
    "counter = 0\n",
    "\n",
    "# Dummy value in case of errors\n",
    "dummy = -1000\n",
    "\n",
    "# variable for determining how many API calls between writing data to CSV\n",
    "write_var = 1000\n",
    "\n",
    "# Start iterating through the date columns\n",
    "for x in df_tMax.columns.values:\n",
    "    \n",
    "    # Skip the columns that are not dates\n",
    "    if (x not in do_not_include):\n",
    "        \n",
    "        # Create Unix time stamp out of the date column\n",
    "        t = pd.to_datetime(df_tMax[x].name)\n",
    "        t = int(t.value / 10**9)\n",
    "        t = str(t)\n",
    "                \n",
    "        # Start iterating through the rows (locations)\n",
    "        for y in range(df_tMax['1/22/20'].values.size):\n",
    "            \n",
    "            # Only do API call if the cell value is 0\n",
    "            if str(df_tMax.iloc[y][x]) == '0':\n",
    "                \n",
    "                print('Cell is 0')\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                print(str(df_tMax.iloc[y][x]))\n",
    "            \n",
    "            counter = counter + 1\n",
    "            print(counter)\n",
    "\n",
    "            # writing CSVs of what I've got so far, for every write_var API calls\n",
    "            if counter % write_var == 0:\n",
    "                \n",
    "                print('1000 API calls')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
